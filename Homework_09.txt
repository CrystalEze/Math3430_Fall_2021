Question 01) Recently we discussed floating point arithmetic, which has become
the standard way of representing numbers on a computer. One of the key aspects
of floating point numbers is that the gap between a number and it's floating
point representation increases with the magnitude of the number. 
This differs from what is called a "fixed
point" representation, where the gap is constant. 

What is an advantage or disadvantage to using floating point instead of fixed
point?

The difference between a floating point number and a fixed point number is that floating point
numbers permits a range of numbers after the decimal which can look similar to scientific notation. A
fixed point number does the opposite of that, it only permits a certain number of digits after the decimal.
One advantage of using floating point is that the calculations can produce an answer that is close to accurate.
A disadvantage to using floating point is that because of the varying digits you have and the large scale of values,
the storage space on your computer won't be able to take it. 


